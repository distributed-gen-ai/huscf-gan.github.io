<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A Distributed Generative AI Approach for Heterogeneous
Multi-Domain Environments under Data Sharing constraints">
  <meta name="keywords" content="Paper, website">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>A Distributed Generative AI Approach for Heterogeneous
Multi-Domain Environments under Data Sharing constraints</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>




<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">A Distributed Generative AI Approach for Heterogeneous
Multi-Domain Environments under Data Sharing constraints</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/youssef-tawfilis-msc-095384197/">Youssef Tawfilis</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/hossam-amer-23b9329b?originalSubdomain=ca">Hossam Amer</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/minar-el-aasser/?originalSubdomain=eg">Minar El-Aasser</a><sup>1</sup>,
            <span class="author-block">
              <a href="https://www.linkedin.com/in/tallal-elshabrawy-2081b0139/?originalSubdomain=eg">Tallal Elshabrawy</a><sup>1</sup>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The German University in Cairo</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/pdf?id=rpbL7pfPYH"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2507.12979"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/youssefga28/HuSCF-GAN"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <img src="./static/images/overall (6).png"
                 class="teaser-image"
                />
        <!-- You can also add a video as a teaser -->
        <!--
        <video id="teaser" autoplay muted loop playsinline height="100%">
            <source src="./static/images/teaser.jpg"
                    type="video/mp4">
        </video> 
        -->
      <h2 class="subtitle has-text-centered">
        Figure 1: HuSCF-GAN Overview
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Federated Learning has gained increasing attention for its ability to enable multiple nodes to collaboratively train machine learning models without sharing their raw data. At the same time, Generative AI—particularly Generative Adversarial Networks (GANs)—have achieved remarkable success across a wide range of domains, such as healthcare, security, and Image Generation. However, training generative models typically requires large datasets and significant computational resources, which are often unavailable in real-world settings. Acquiring such resources can be costly and inefficient, especially when many underutilized devices—such as IoT devices and edge devices—with varying capabilities remain idle. Moreover, obtaining large datasets is challenging due to privacy concerns and copyright restrictions, as most devices are unwilling to share their data. To address these challenges, we propose a novel approach for decentralized GAN training that enables the utilization of distributed data and underutilized, low-capability devices while not sharing data in its raw form. Our approach is designed to tackle key challenges in decentralized environments, combining KLD-weighted Clustered Federated Learning to address the issues of data heterogeneity and multi-domain datasets, with Heterogeneous U-Shaped split learning to tackle the challenge of device heterogeneity under strict data sharing constraints—ensuring that no labels or raw data, whether real or synthetic, are ever shared between nodes. Experimental results shows that our approach demonstrates consistent and significant improvements across key performance metrics, where it achieves an average 10% boost in classification metrics (up to 60% in multi-domain non-IID settings), 1.1×—3× higher image generation scores for the MNIST family datasets, and 2×—70× lower FID scores for higher resolution datasets, in much lower latency compared to several benchmarks.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Motivation -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motivation</h2>
        <div class="content has-text-justified">
          <p>
            Training modern generative AI models typically requires centralized access to large datasets and powerful compute infrastructure,
            which is often infeasible in real-world environments where data is siloed due to privacy, security, or legal constraints.
            Meanwhile, vast numbers of edge and IoT devices remain underutilized, each with limited and highly variable computational capabilities.
            Existing decentralized paradigms—such as federated learning and split learning—address parts of this problem but fail to jointly
            handle device heterogeneity, non-IID data, multi-domain environments, and strict data-sharing constraints.
            As illustrated in <b>Figure&nbsp;2</b>, current learning paradigms differ in how they trade off privacy, computation, and communication,
            while prior distributed GAN approaches address only subsets of these challenges.
            These limitations motivate a unified framework that enables collaborative generative model training across heterogeneous,
            privacy-sensitive, and multi-domain environments without sharing raw data or labels.
          </p>
        </div>
      </div>
    </div>
    
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <figure class="image">
          <img src="./static/images/sl-1.png" alt="Learning paradigms comparison">
          <figcaption class="has-text-centered">
            Figure 2: Comparison of Federated Learning, Split Learning, and U-shaped Split Learning,
            highlighting privacy and system trade-offs.
          </figcaption>
        </figure>
      </div>
  </div>

    <!-- Methodology -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Methodology</h2>
        <div class="content has-text-justified">
          <p>
            We propose <b>HuSCF-GAN</b>, a distributed generative learning framework that combines heterogeneous U-shaped split learning
            with clustered federated learning.
            As shown in <b>Figure&nbsp;3</b>, each client’s generator and discriminator are split between the client and a shared server,
            enabling devices with different computational and communication capabilities to participate efficiently while keeping raw data
            and labels local.
            The server first determines optimal, client-specific split points using a genetic algorithm to minimize overall training latency.
            Training then proceeds via heterogeneous U-shaped split learning, illustrated in <b>Figure&nbsp;4</b>, where only intermediate
            activations and gradients are exchanged.
            Periodically, the server clusters clients based on discriminator activations and performs clustered federated aggregation,
            weighting updates using both dataset size and divergence scores.
            Together, these components allow HuSCF-GAN to robustly handle device heterogeneity, non-IID data, and multi-domain settings
            under strict data-sharing constraints.
          </p>
        </div>
      </div>
    </div>

<div class="columns is-centered">
  <div class="column is-four-fifths">
    <figure class="image">
      <img src="./static/images/workflow-1.png" alt="HuSCF-GAN workflow">
      <figcaption class="has-text-centered">
        Figure 3: HuSCF-GAN training pipeline is composed of optimal split selection, heterogeneous U-shaped split learning,
        activation-based clustering, and clustered federated aggregation.
      </figcaption>
    </figure>
  </div>
</div>

<br>

<div class="columns is-centered">
  <div class="column is-four-fifths">
    <figure class="image">
      <img src="./static/images/hetsplit.png" alt="Heterogeneous U-shaped split learning">
      <figcaption class="has-text-centered">
        Figure 4: Heterogeneous U-shaped split learning where different clients use different cut points,
        while raw data and labels remain local.
      </figcaption>
    </figure>
  </div>
</div>


    <!-- Evaluation -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Evaluation</h2>
        <div class="content has-text-justified">
          <p>
            HuSCF-GAN is evaluated across a wide range of realistic scenarios, including IID and non-IID data distributions,
        single-domain and multi-domain environments, and highly heterogeneous edge-device configurations.
        The diversity of datasets used in the evaluation is illustrated in <b>Figure&nbsp;5</b>, spanning handwritten digits,
        fashion images, medical imaging, natural images, and audio data.
        Across all settings, HuSCF-GAN consistently outperforms state-of-the-art distributed GAN baselines.
        It achieves an average <b>~10% improvement in downstream classification performance</b>, with gains reaching
        <b>up to 50–60%</b> in challenging multi-domain non-IID scenarios.
        In terms of generative quality, HuSCF-GAN delivers <b>1.1×–3× higher image generation scores</b> on MNIST-family datasets
        and <b>2×–70× lower FID scores</b> on higher-resolution datasets.
        Crucially, HuSCF-GAN also improves efficiency, achieving <b>significantly lower training latency</b> than competing
        distributed GAN frameworks—reducing per-iteration latency by at least <b>5×</b> and up to <b>58×</b> in heterogeneous and multi-domain
        settings—while maintaining stable convergence.
        These results demonstrate that HuSCF-GAN delivers both <b>performance gains and practical scalability</b> without
        sacrificing efficiency.
          </p>
        </div>
      </div>
    </div>

<div class="columns is-centered">
  <div class="column is-four-fifths">
    <figure class="image">
      <img src="./static/images/Screenshot 2025-12-27 135944.png" alt="Evaluation datasets">
      <figcaption class="has-text-centered">
        Figure 5: Datasets used for evaluation across image, higher resolution images, medical imaging, and audio domains.
      </figcaption>
    </figure>
  </div>
</div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{tawfilis2025distributedgenerativeaiapproach,
      title={A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints}, 
      author={Youssef Tawfilis and Hossam Amer and Minar El-Aasser and Tallal Elshabrawy},
      year={2025},
      eprint={2507.12979},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2507.12979}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <center><p>
            This website (<a href="https://github.com/paper-website/paper-website.github.io">source code</a>) was adapted from the popular <a
            href="https://nerfies.github.io">Nerfies</a> project page and is licensed under a <br><a rel="license"
            href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p></center>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
